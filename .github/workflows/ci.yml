name: CI

on:
  push:
    branches:
      - main
      - master
      - develop
      - test
      - 'feature/**'
      - 'codex/**'
  pull_request: {}
  workflow_dispatch: {}

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  tests:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            echo "No requirements.txt found; skipping."
          fi
          pip install pytest

      - name: Detect tests
        id: detect
        shell: bash
        run: |
          set -euo pipefail
          if ls -1 test*.py tests/*.py tests/**/*.py */test_*.py 2>/dev/null | head -n1; then
            echo "has_tests=1" >> "$GITHUB_OUTPUT"
          else
            echo "has_tests=0" >> "$GITHUB_OUTPUT"
          fi

      - name: Run pytest
        if: steps.detect.outputs.has_tests == '1'
        shell: bash
        run: |
          set -euo pipefail
          pytest --maxfail=1 --disable-warnings -q --ignore=scripts

      - name: Skip note (no tests found)
        if: steps.detect.outputs.has_tests != '1'
        shell: bash
        run: |
          set -euo pipefail
          echo "No test files detected; skipping pytest."

  pipeline-check:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    permissions:
      id-token: write
      contents: read

    env:
      PROJECT_ID: esp32cam-472912
      REGION: asia-east1
      SERVICE_URL: ${{ vars.SERVICE_URL }}
      PIPELINE_ROOT: ${{ vars.PIPELINE_ROOT }}
      GCS_INBOX: ${{ vars.GCS_INBOX }}
      SAMPLES_ROOT_URI: ${{ vars.SAMPLES_ROOT_URI }}
      PIPELINE_DEF: ${{ vars.PIPELINE_DEF }}
      CLOUD_RUN_HEALTH_PATH: ${{ vars.CLOUD_RUN_HEALTH_PATH }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Auth to GCP via OIDC (ADC)
        id: gcp-auth
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
          service_account: ${{ secrets.GCP_SA_EMAIL }}
          create_credentials_file: true
          export_environment_variables: true

      - name: Export ADC env
        shell: bash
        run: |
          set -euo pipefail
          echo "CLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE=${{ steps.gcp-auth.outputs.credentials_file_path }}" >> "$GITHUB_ENV"
          echo "GOOGLE_APPLICATION_CREDENTIALS=${{ steps.gcp-auth.outputs.credentials_file_path }}" >> "$GITHUB_ENV"

      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.PROJECT_ID }}
          version: '>= 477.0.0'

      - name: Ensure jq
        shell: bash
        run: |
          set -euo pipefail
          command -v jq >/dev/null || { sudo apt-get update -y && sudo apt-get install -y jq; }

      - name: Sanity check env
        shell: bash
        run: |
          set -euo pipefail
          for v in SERVICE_URL PIPELINE_ROOT GCS_INBOX SAMPLES_ROOT_URI; do
            if [ -z "${!v:-}" ]; then
              echo "Missing required variable: $v (set in Settings → Actions → Variables)" >&2
              exit 1
            fi
          done

          if [ -z "${PIPELINE_DEF:-}" ]; then
            echo "Missing variable: PIPELINE_DEF" >&2
            exit 1
          fi

          if echo "${PIPELINE_DEF}" | grep -q '^gs://'; then
            gsutil ls "${PIPELINE_DEF}" >/dev/null 2>&1 || { echo "Missing ${PIPELINE_DEF} in GCS" >&2; exit 1; }
          else
            [ -f "${PIPELINE_DEF}" ] || { echo "Missing ${PIPELINE_DEF} in repo" >&2; exit 1; }
          fi

          echo "SERVICE_URL=${SERVICE_URL}"
          echo "PIPELINE_ROOT=${PIPELINE_ROOT}"
          echo "GCS_INBOX=${GCS_INBOX}"
          echo "SAMPLES_ROOT_URI=${SAMPLES_ROOT_URI}"
          echo "PIPELINE_DEF=${PIPELINE_DEF}"
          echo "CLOUD_RUN_HEALTH_PATH=${CLOUD_RUN_HEALTH_PATH:-/health}"

      - name: Run Vertex Pipeline (enroll batch) - version compatible
        id: run_pipeline
        shell: bash
        run: |
          set -euo pipefail
          JOB_NAME=""
          if gcloud ai pipeline-jobs --help >/dev/null 2>&1; then
            JOB_NAME=$(gcloud ai pipeline-jobs create "enroll-$(date +%Y%m%d-%H%M%S)" \
              --region="${REGION}" \
              --pipeline-definition-file="${PIPELINE_DEF}" \
              --pipeline-root="${PIPELINE_ROOT}" \
              --display-name="Enroll Batch via CI" \
              --labels=ci=codex,stage=enroll \
              --format="value(name)")
          elif gcloud beta ai pipeline-jobs --help >/dev/null 2>&1; then
            JOB_NAME=$(gcloud beta ai pipeline-jobs create "enroll-$(date +%Y%m%d-%H%M%S)" \
              --region="${REGION}" \
              --pipeline-definition-file="${PIPELINE_DEF}" \
              --pipeline-root="${PIPELINE_ROOT}" \
              --display-name="Enroll Batch via CI" \
              --labels=ci=codex,stage=enroll \
              --format="value(name)")
          elif gcloud ai pipelines --help >/dev/null 2>&1; then
            OUT=$(gcloud ai pipelines run \
              --region="${REGION}" \
              --pipeline-definition-file="${PIPELINE_DEF}" \
              --pipeline-root="${PIPELINE_ROOT}" \
              --display-name="Enroll Batch via CI" \
              --labels=ci=codex,stage=enroll 2>&1 | tee /tmp/pipelines_run.out)
            JOB_NAME=$(grep -o 'projects/.*/locations/.*/pipelineJobs/[a-zA-Z0-9_-]*' /tmp/pipelines_run.out | head -n1 || true)
          else
            echo "::warning::No Vertex Pipelines command available; skipping pipeline submission."
          fi
          echo "job_name=${JOB_NAME}" >> "$GITHUB_OUTPUT"
          echo "Submitted: ${JOB_NAME}"

      - name: Wait for enroll to finish
        if: ${{ steps.run_pipeline.outputs.job_name && steps.run_pipeline.outputs.job_name != '' }}
        shell: bash
        run: |
          set -euo pipefail
          JOB_NAME="${{ steps.run_pipeline.outputs.job_name }}"
          if gcloud ai pipeline-jobs --help >/dev/null 2>&1; then
            gcloud ai pipeline-jobs wait "${JOB_NAME}" --region="${REGION}"
          elif gcloud beta ai pipeline-jobs --help >/dev/null 2>&1; then
            gcloud beta ai pipeline-jobs wait "${JOB_NAME}" --region="${REGION}"
          else
            echo "::notice::No 'pipeline-jobs wait' available; continuing."
          fi

      - name: Get Cloud Run ID token (gcloud, no impersonation)
        id: idt
        shell: bash
        run: |
          set -euo pipefail
          BASE="${SERVICE_URL%/}"
          # 清掉可能殘留的 impersonation 設定
          gcloud config unset auth/impersonate_service_account || true
          echo "Active account:"; gcloud auth list --filter=status:ACTIVE
          echo "ADC file: ${GOOGLE_APPLICATION_CREDENTIALS:-<none>}"
          gcloud --version
          # 先用 ADC 取 ID Token；若該子命令不存在或失敗，改用 google-auth 備援
          if IDT="$(gcloud auth application-default print-identity-token --audiences="$BASE" 2>/dev/null)"; then
            :
          else
            IDT="$(python3 -c 'import os; from google.auth.transport.requests import Request; from google.oauth2.id_token import fetch_id_token; aud=os.environ["BASE"]; print(fetch_id_token(Request(), aud))')"
          fi
          echo "id_token=$IDT" >> "$GITHUB_OUTPUT"

      - name: Probe Cloud Run /health (no impersonation)
        shell: bash
        run: |
          set -euo pipefail
          URL="${SERVICE_URL%/}${CLOUD_RUN_HEALTH_PATH:-/health}"
          echo "GET (no-auth) $URL"
          HTTP=$(curl -sS -o /tmp/health_noauth.out -w "%{http_code}" "$URL" || true)
          echo "HTTP(no-auth)=$HTTP"
          if [ "$HTTP" -ge 200 ] && [ "$HTTP" -lt 300 ]; then
            cat /tmp/health_noauth.out
            exit 0
          fi
          echo "---- body(no-auth) ----"; cat /tmp/health_noauth.out || true; echo "-----------------------"

          echo "GET (auth) $URL"
          n=0
          while :; do
            HTTP2=$(curl -sS -H "Authorization: Bearer ${{ steps.idt.outputs.id_token }}" -o /tmp/health_auth.out -w "%{http_code}" "$URL" || true)
            echo "HTTP(auth)=$HTTP2"
            if [ "$HTTP2" -ge 200 ] && [ "$HTTP2" -lt 300 ]; then
              echo "---- body(auth) ----"; cat /tmp/health_auth.out || true; echo "--------------------"
              break
            fi
            n=$((n+1))
            if [ $n -ge 5 ]; then
              echo "Health check failed after retries; collecting diagnostics"
              export IDT="${{ steps.idt.outputs.id_token }}"
              gcloud info || true
              gcloud config list || true
              python3 - <<'PY'
                import os,sys,jwt,base64,json
                tok=os.environ.get("IDT")
                h=jwt.get_unverified_header(tok); p=jwt.decode(tok, options={"verify_signature":False})
                print("IDT.header=",h); print("IDT.payload=",json.dumps(p,indent=2))
              PY
              exit 1
            fi
            sleep 3
          done

      - name: Upload one test photo per person (trigger Eventarc)
        shell: bash
        run: |
          set -euo pipefail
          echo "Scanning ${SAMPLES_ROOT_URI}/ for subfolders..."
          for dir in $(gsutil ls "${SAMPLES_ROOT_URI}/"); do
            person=$(basename "${dir%/}")
            src="${dir}01.jpg"
            ts=$(date +%s)
            inbox="${GCS_INBOX%/}"
            dst="${inbox}/ci_${person}_${ts}.jpg"
            echo "cp ${src} -> ${dst}"
            if gsutil -q stat "${src}"; then
              gsutil cp "${src}" "${dst}"
            else
              echo "Skip (no 01.jpg): ${src}"
            fi
          done

      - name: Recognize via API for each person (pure bash)
        shell: bash
        run: |
          set -euo pipefail
          fails=0
          for dir in $(gsutil ls "${SAMPLES_ROOT_URI}/"); do
            person=$(basename "${dir%/}")
            img="/tmp/02_${person}.jpg"
            if gsutil -q stat "${dir}02.jpg"; then
              gsutil cp "${dir}02.jpg" "$img"
              b64=$(base64 -w 0 "$img" 2>/dev/null || base64 "$img" | tr -d '\n')
              payload=$(jq -cn --arg b64 "$b64" --arg person "$person" \
                         '{images: ["data:image/jpeg;base64," + $b64], person: $person}')
              echo "POST /detect_face for ${person}"
              if ! curl -fsS -X POST "${SERVICE_URL%/}/detect_face" \
                    -H "Content-Type: application/json" -d "$payload" >/dev/null; then
                echo "FAIL: ${person}"
                fails=$((fails+1))
              fi
            else
              echo "Skip (no 02.jpg): ${dir}02.jpg"
            fi
          done
          echo "fails=${fails}"
          test "$fails" -eq 0

      - name: Upload logs (if any)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-check-artifacts
          path: "**/*.log"
          if-no-files-found: ignore
