name: CI

on:
  push:
    branches:
      - main
      - master
      - develop
      - test
      - feature/**
  pull_request:
  workflow_dispatch: {}

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  tests:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            echo "No requirements.txt found; skipping."
          fi
          pip install pytest

      - name: Detect tests
        id: detect
        run: |
          if ls -1 test*.py tests/*.py tests/**/*.py */test_*.py 2>/dev/null | head -n1; then
            echo "has_tests=1" >> "$GITHUB_OUTPUT"
          else
            echo "has_tests=0" >> "$GITHUB_OUTPUT"
          fi

      - name: Run pytest
        if: steps.detect.outputs.has_tests == '1'
        run: pytest --maxfail=1 --disable-warnings -q --ignore=scripts

      - name: Skip note (no tests found)
        if: steps.detect.outputs.has_tests != '1'
        run: echo "No test files detected; skipping pytest."

  pipeline-check:
    # needs: tests   # 若要先跑單元測試再跑，取消註解
    runs-on: ubuntu-latest
    timeout-minutes: 45
    permissions:
      id-token: write
      contents: read

    env:
      PROJECT_ID: esp32cam-472912
      REGION: asia-east1

      # ★ 這四個建議放在 repo → Settings → Secrets and variables → Actions → Variables
      SERVICE_URL: ${{ vars.SERVICE_URL }}           # 例：https://esp32-cam-jim-665759721336.asia-east1.run.app
      PIPELINE_ROOT: ${{ vars.PIPELINE_ROOT }}       # 例：gs://esp32cam-472912-vertex-pipelines-asia-east1/kfp-root
      GCS_INBOX: ${{ vars.GCS_INBOX }}               # 例：gs://esp32cam-472912-faces/new_photos
      SAMPLES_ROOT_URI: ${{ vars.SAMPLES_ROOT_URI }} # 例：gs://esp32cam-472912-vertex-data/faces/personA

      PIPELINE_DEF: pipelines/face_enroll_recognize.json

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Auth to GCP via OIDC
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
          service_account: ${{ secrets.GCP_SA_EMAIL }}

      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.PROJECT_ID }}

      - name: Sanity check env
        run: |
          set -e
          for v in SERVICE_URL PIPELINE_ROOT GCS_INBOX SAMPLES_ROOT_URI; do
            if [ -z "${!v}" ]; then
              echo "Missing required variable: $v (set repo variable in Settings → Actions → Variables)"; exit 1;
            fi
          done
          if [ ! -f "${PIPELINE_DEF}" ]; then
            echo "Missing ${PIPELINE_DEF} in repo"; exit 1;
          fi
          echo "SERVICE_URL=${SERVICE_URL}"
          echo "PIPELINE_ROOT=${PIPELINE_ROOT}"
          echo "GCS_INBOX=${GCS_INBOX}"
          echo "SAMPLES_ROOT_URI=${SAMPLES_ROOT_URI}"

      - name: Run Vertex Pipeline (enroll batch)
        run: |
          gcloud ai pipeline-jobs create "enroll-$(date +%Y%m%d-%H%M%S)" \
            --region="${REGION}" \
            --pipeline-definition-file="${PIPELINE_DEF}" \
            --pipeline-root="${PIPELINE_ROOT}" \
            --display-name="Enroll Batch via CI" \
            --labels=ci=codex,stage=enroll \
            --format="value(name)"

      - name: Wait for enroll to finish
        run: |
          JOB_ID=$(gcloud ai pipeline-jobs list --region="${REGION}" \
            --filter="labels.ci=codex AND labels.stage=enroll" --format="value(NAME)" | head -n1)
          echo "JOB_ID=$JOB_ID"
          gcloud ai pipeline-jobs wait "$JOB_ID" --region="${REGION}"

      - name: Upload one test photo per person (trigger Eventarc)
        run: |
          set -e
          echo "Scanning ${SAMPLES_ROOT_URI}/ for subfolders..."
          # 列出一層子資料夾，例如 .../personA/Alanna/
          for dir in $(gsutil ls "${SAMPLES_ROOT_URI}/"); do
            person=$(basename "${dir%/}")
            src="${dir}01.jpg"
            ts=$(date +%s)
            # 確保 GCS_INBOX 沒有尾斜線
            inbox="${GCS_INBOX%/}"
            dst="${inbox}/ci_${person}_${ts}.jpg"
            echo "cp ${src} -> ${dst}"
            if gsutil -q stat "${src}"; then
              gsutil cp "${src}" "${dst}"
            else
              echo "Skip (no 01.jpg): ${src}"
            fi
          done

      - name: Recognize via API for each person
        run: |
          set -e
          fails=0
          # 先寫入一個臨時 Python 檔，避免 heredoc 解析問題
          cat > /tmp/post_detect.py <<'PY'
import base64, json, os, sys, urllib.request
img_path = sys.argv[1]
person = sys.argv[2]
service_url = os.environ["SERVICE_URL"].rstrip("/") + "/detect_face"
with open(img_path, "rb") as f:
    b64 = base64.b64encode(f.read()).decode()
payload = json.dumps({"images": [f"data:image/jpeg;base64,{b64}"], "person": person}).encode()
req = urllib.request.Request(service_url, data=payload, headers={"Content-Type": "application/json"})
resp = urllib.request.urlopen(req, timeout=120)
print(resp.read().decode())
PY
          for dir in $(gsutil ls "${SAMPLES_ROOT_URI}/"); do
            person=$(basename "${dir%/}")
            img="/tmp/02_${person}.jpg"
            if gsutil -q stat "${dir}02.jpg"; then
              gsutil cp "${dir}02.jpg" "$img"
              echo "POST /detect_face for ${person}"
              if ! python3 /tmp/post_detect.py "$img" "$person"; then
                echo "FAIL: ${person}"
                fails=$((fails+1))
              fi
            else
              echo "Skip (no 02.jpg): ${dir}02.jpg"
            fi
          done
          echo "fails=${fails}"
          if [ "$fails" -ne 0 ]; then
            exit 1
          fi

      - name: Upload logs (if any)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-check-artifacts
          path: "**/*.log"
          if-no-files-found: ignore
