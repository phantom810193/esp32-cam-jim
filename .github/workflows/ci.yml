name: CI

on:
  push:
    branches:
      - main
      - master
      - develop
      - test
      - feature/**
  pull_request:
  workflow_dispatch: {}

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  tests:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            echo "No requirements.txt found; skipping."
          fi
          pip install pytest

      - name: Detect tests
        id: detect
        run: |
          if ls -1 test*.py tests/*.py tests/**/*.py */test_*.py 2>/dev/null | head -n1; then
            echo "has_tests=1" >> "$GITHUB_OUTPUT"
          else
            echo "has_tests=0" >> "$GITHUB_OUTPUT"
          fi

      - name: Run pytest
        if: steps.detect.outputs.has_tests == '1'
        run: pytest --maxfail=1 --disable-warnings -q --ignore=scripts

      - name: Skip note (no tests found)
        if: steps.detect.outputs.has_tests != '1'
        run: echo "No test files detected; skipping pytest."

  pipeline-check:
    # needs: tests   # 若要先跑本地測試再跑，移除註解
    runs-on: ubuntu-latest
    timeout-minutes: 45
    permissions:
      id-token: write
      contents: read

    env:
      # ------- GCP 基本 -------
      PROJECT_ID: esp32cam-472912
      REGION: asia-east1

      # ------- 從 repo Variables 讀取（建議在 Settings → Secrets and variables → Actions → Variables 設定）-------
      SERVICE_URL: ${{ vars.SERVICE_URL }}     # 例：https://esp32-cam-jim-665759721336.asia-east1.run.app
      PIPELINE_ROOT: ${{ vars.PIPELINE_ROOT }} # 例：gs://esp32cam-472912-vertex-pipelines-asia-east1/kfp-root
      GCS_INBOX: ${{ vars.GCS_INBOX }}         # 例：gs://esp32cam-472912-faces/new_photos
      SAMPLES_ROOT_URI: ${{ vars.SAMPLES_ROOT_URI }} # 例：gs://esp32cam-472912-vertex-data/faces/personA
      PIPELINE_DEF: pipelines/face_enroll_recognize.json

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Auth to GCP via OIDC
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
          service_account: ${{ secrets.GCP_SA_EMAIL }}

      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.PROJECT_ID }}

      - name: Sanity check (required env/vars exist)
        run: |
          set -e
          : "${SERVICE_URL:?SERVICE_URL missing (set repo variable)}"
          : "${PIPELINE_ROOT:?PIPELINE_ROOT missing (set repo variable)}"
          : "${GCS_INBOX:?GCS_INBOX missing (set repo variable)}"
          : "${SAMPLES_ROOT_URI:?SAMPLES_ROOT_URI missing (set repo variable)}"
          test -f "${PIPELINE_DEF}" || (echo "Missing ${PIPELINE_DEF}" && exit 1)
          echo "SERVICE_URL=${SERVICE_URL}"
          echo "PIPELINE_ROOT=${PIPELINE_ROOT}"
          echo "GCS_INBOX=${GCS_INBOX}"
          echo "SAMPLES_ROOT_URI=${SAMPLES_ROOT_URI}"

      - name: Run Vertex Pipeline (enroll batch)
        run: |
          gcloud ai pipeline-jobs create "enroll-$(date +%Y%m%d-%H%M%S)" \
            --region="${REGION}" \
            --pipeline-definition-file="${PIPELINE_DEF}" \
            --pipeline-root="${PIPELINE_ROOT}" \
            --display-name="Enroll Batch via CI" \
            --labels=ci=codex,stage=enroll \
            --format="value(name)"

      - name: Wait for enroll to finish
        run: |
          JOB_ID=$(gcloud ai pipeline-jobs list --region="${REGION}" \
            --filter="labels.ci=codex AND labels.stage=enroll" --format="value(NAME)" | head -n1)
          echo "JOB_ID=$JOB_ID"
          gcloud ai pipeline-jobs wait "$JOB_ID" --region="${REGION}"

      - name: Upload one test photo per person (trigger Eventarc)
        run: |
          set -e
          echo "Scanning ${SAMPLES_ROOT_URI}/ for subfolders..."
          for dir in $(gsutil ls "${SAMPLES_ROOT_URI}/"); do
            person=$(basename "${dir%/}")
            src="${dir}01.jpg"
            ts=$(date +%s)
            dst="${GCS_INBOX%/}/ci_${person}_${ts}.jpg"
            echo "cp $src -> $dst"
            gsutil cp "$src" "$dst" || echo "Skip (no 01.jpg): $src"
          done

      - name: Recognize via API for each person
        run: |
          set -e
          fails=0
          for dir in $(gsutil ls "${SAMPLES_ROOT_URI}/"); do
            person=$(basename "${dir%/}")
            img="/tmp/02_${person}.jpg"
            if gsutil cp "${dir}02.jpg" "$img"; then
              IMG="$img" PERSON="$person" python3 - <<'PY' || fails=$((fails+1))
import base64, json, os, urllib.request
img=os.environ["IMG"]; person=os.environ["PERSON"]
url=os.environ["SERVICE_URL"].rstrip("/") + "/detect_face"
with open(img,"rb") as f: b64=base64.b64encode(f.read()).decode()
payload=json.dumps({"images":[f"data:image/jpeg;base64,{b64}"], "person": person}).encode()
print("POST", url, "for", person)
resp=urllib.request.urlopen(urllib.request.Request(url, data=payload, headers={"Content-Type":"application/json"}), timeout=120)
print(resp.read().decode())
PY
            else
              echo "Skip (no 02.jpg): ${person}"
            fi
          done
          echo "fails=$fails"
          [ "$fails" -eq 0 ] || exit 1

      - name: Upload logs (if any)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-check-artifacts
          path: "**/*.log"
          if-no-files-found: ignore
