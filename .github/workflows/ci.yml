name: CI

on:
  push:
    branches:
      - main
      - master
      - develop
      - test
      - 'feature/**'
  pull_request: {}
  workflow_dispatch: {}

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  tests:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            echo "No requirements.txt found; skipping."
          fi
          pip install pytest

      - name: Detect tests
        id: detect
        shell: bash
        run: |
          set -euo pipefail
          if ls -1 test*.py tests/*.py tests/**/*.py */test_*.py 2>/dev/null | head -n1; then
            echo "has_tests=1" >> "$GITHUB_OUTPUT"
          else
            echo "has_tests=0" >> "$GITHUB_OUTPUT"
          fi

      - name: Run pytest
        if: steps.detect.outputs.has_tests == '1'
        shell: bash
        run: |
          set -euo pipefail
          pytest --maxfail=1 --disable-warnings -q --ignore=scripts

      - name: Skip note (no tests found)
        if: steps.detect.outputs.has_tests != '1'
        shell: bash
        run: |
          set -euo pipefail
          echo "No test files detected; skipping pytest."

  pipeline-check:
    # needs: tests   # 若要先跑單元測試再跑，取消註解
    runs-on: ubuntu-latest
    timeout-minutes: 45
    permissions:
      id-token: write
      contents: read

    env:
      PROJECT_ID: esp32cam-472912
      REGION: asia-east1

      # ★ 這四個建議放在 repo → Settings → Secrets and variables → Actions → Variables
      SERVICE_URL: ${{ vars.SERVICE_URL }}           # 例：https://esp32-cam-jim-XXXX.asia-east1.run.app
      PIPELINE_ROOT: ${{ vars.PIPELINE_ROOT }}       # 例：gs://esp32cam-472912-vertex-pipelines-asia-east1/kfp-root
      GCS_INBOX: ${{ vars.GCS_INBOX }}               # 例：gs://esp32cam-472912-faces/new_photos
      SAMPLES_ROOT_URI: ${{ vars.SAMPLES_ROOT_URI }} # 例：gs://esp32cam-472912-vertex-data/faces/personA

      PIPELINE_DEF: pipelines/face_enroll_recognize.json

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Auth to GCP via OIDC
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WIF_PROVIDER }}
          service_account: ${{ secrets.GCP_SA_EMAIL }}

      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.PROJECT_ID }}

      - name: Sanity check env
        shell: bash
        run: |
          set -euo pipefail
          for v in SERVICE_URL PIPELINE_ROOT GCS_INBOX SAMPLES_ROOT_URI; do
            if [ -z "${!v:-}" ]; then
              echo "Missing required variable: $v (set repo variable in Settings → Actions → Variables)" >&2
              exit 1
            fi
          done
          if [ ! -f "${PIPELINE_DEF}" ]; then
            echo "Missing ${PIPELINE_DEF} in repo" >&2
            exit 1
          fi
          echo "SERVICE_URL=${SERVICE_URL}"
          echo "PIPELINE_ROOT=${PIPELINE_ROOT}"
          echo "GCS_INBOX=${GCS_INBOX}"
          echo "SAMPLES_ROOT_URI=${SAMPLES_ROOT_URI}"

      - name: Run Vertex Pipeline (enroll batch)
        shell: bash
        run: |
          set -euo pipefail
          gcloud ai pipeline-jobs create "enroll-$(date +%Y%m%d-%H%M%S)" \
            --region="${REGION}" \
            --pipeline-definition-file="${PIPELINE_DEF}" \
            --pipeline-root="${PIPELINE_ROOT}" \
            --display-name="Enroll Batch via CI" \
            --labels=ci=codex,stage=enroll \
            --format="value(name)"

      - name: Wait for enroll to finish
        shell: bash
        run: |
          set -euo pipefail
          JOB_ID=$(gcloud ai pipeline-jobs list --region="${REGION}" \
            --filter="labels.ci=codex AND labels.stage=enroll" --format="value(NAME)" | head -n1)
          echo "JOB_ID=$JOB_ID"
          gcloud ai pipeline-jobs wait "$JOB_ID" --region="${REGION}"

      - name: Upload one test photo per person (trigger Eventarc)
        shell: bash
        run: |
          set -euo pipefail
          echo "Scanning ${SAMPLES_ROOT_URI}/ for subfolders..."
          # 列出一層子資料夾，例如 .../personA/Alanna/
          for dir in $(gsutil ls "${SAMPLES_ROOT_URI}/"); do
            person=$(basename "${dir%/}")
            src="${dir}01.jpg"
            ts=$(date +%s)
            # 確保 GCS_INBOX 沒有尾斜線
            inbox="${GCS_INBOX%/}"
            dst="${inbox}/ci_${person}_${ts}.jpg"
            echo "cp ${src} -> ${dst}"
            if gsutil -q stat "${src}"; then
              gsutil cp "${src}" "${dst}"
            else
              echo "Skip (no 01.jpg): ${src}"
            fi
          done

      - name: Recognize via API for each person
        shell: bash
        run: |
          set -euo pipefail
          fails=0
          for dir in $(gsutil ls "${SAMPLES_ROOT_URI}/"); do
            person=$(basename "${dir%/}")
            if gsutil -q stat "${dir}02.jpg"; then
              img="/tmp/02_${person}.jpg"
              gsutil cp "${dir}02.jpg" "$img"
              echo "POST /detect_face for ${person}"
              IMG="$img" PERSON="$person" python3 -c "import base64,json,os,urllib.request
img=os.environ['IMG']; person=os.environ['PERSON']
service_url=os.environ['SERVICE_URL'].rstrip('/')+'/detect_face'
with open(img,'rb') as f:
  b64=base64.b64encode(f.read()).decode()
payload=json.dumps({'images':['data:image/jpeg;base64,'+b64],'person':person}).encode()
req=urllib.request.Request(service_url,data=payload,headers={'Content-Type':'application/json'})
with urllib.request.urlopen(req,timeout=120) as resp:
  print(resp.read().decode())" || fails=\$((fails+1))
            else
              echo "Skip (no 02.jpg): ${dir}02.jpg"
            fi
          done
          echo "fails=${fails}"
          test "$fails" -eq 0

      - name: Upload logs (if any)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-check-artifacts
          path: "**/*.log"
          if-no-files-found: ignore
